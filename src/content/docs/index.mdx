---
title: Vibesafe
description: AI-generated code you can actually trust in production
template: splash
hero:
  tagline: Write Python specs with doctests. Get implementations that pass tests. Deploy with cryptographic guarantees.
  actions:
    - text: Get Started
      link: /getting-started/
      icon: right-arrow
      variant: primary
    - text: GitHub
      link: https://github.com/julep-ai/vibesafe
      icon: external
---

import { Card, CardGrid } from '@astrojs/starlight/components';

## The Problem

You know the drill: Ask ChatGPT for code, copy-paste it, hope it works. Ask again tomorrow, get different code. Deploy to production? Good luck.

**AI code generation is powerful but fundamentally broken for production use:**

- Non-deterministic (same question â‰  same answer)
- No verification (could be wrong, could have bugs)
- Manual process (copy-paste, review, cross fingers)
- Zero audit trail (who generated what when?)
- Drift detection? Doesn't exist

We built Vibesafe because we were tired of treating AI-generated code like a liability instead of an asset.

## The Solution

What if AI-generated code was:
- âœ… **Deterministic** - same spec always produces the same code
- âœ… **Verified** - must pass tests before it can be used
- âœ… **Reproducible** - cryptographic hashing guarantees consistency
- âœ… **Importable** - no copy-paste, just regular Python imports
- âœ… **Auditable** - every checkpoint has metadata and hashes

That's Vibesafe. It's a build system for AI-generated code.

## Show Me Code

```python
# 1. Write a spec with doctests
from vibesafe import vibesafe, VibeCoded

@vibesafe
def analyze(text: str) -> dict:
    """
    Perform sentiment analysis.

    >>> analyze("I love this!")
    {'sentiment': 'positive', 'score': 0.95}
    """
    raise VibeCoded()
```

```bash
# 2. Compile (calls LLM, generates implementation)
$ vibesafe compile --target app.sentiment/analyze
âœ“ Extracted spec
âœ“ Called LLM (gpt-4o-mini)
âœ“ Generated implementation
âœ“ Saved checkpoint

# 3. Test (runs doctests + type checking + linting)
$ vibesafe test --target app.sentiment/analyze
âœ“ Doctest 1/1 passed
âœ“ Type check passed (mypy)
âœ“ Lint passed (ruff)

# 4. Save (marks as production-ready)
$ vibesafe save --target app.sentiment/analyze
âœ“ Checkpoint activated
```

```python
# 5. Use it (just regular imports)
from app.sentiment import analyze

print(analyze("I love this!"))  # {'sentiment': 'positive', 'score': 0.95}
```

**The AI-generated implementation is cached, tested, and frozen.** Change the spec? Hash changes, and you know immediately.

## How It Actually Works

Vibesafe computes a **spec hash** from:
- Function signature (`fibonacci(n: int) -> int`)
- Docstring + doctests
- Model config (temperature, seed, etc.)
- Dependencies

**Same hash = same code.** Always.

When you compile:
1. Spec â†’ hash (e.g., `5a72e9...`)
2. Check cache (have we generated this before?)
3. If miss: call LLM with deterministic seed
4. Validate generated code (parse, type check)
5. Save to `.vibesafe/checkpoints/<hash>/impl.py`
6. Run tests (doctests + quality gates)
7. Mark as active in index

When you import:
1. Load active checkpoint from index
2. In prod mode: verify hash matches (fail fast if not)
3. Return function object

No LLM calls in production. No API keys needed. Just loading Python files.

## Two Modes

**Dev mode** (local development):
- Hash mismatch? Warn and regenerate
- Missing checkpoint? Generate automatically
- Fast iteration, immediate feedback

**Prod mode** (deployments):
- Hash mismatch? Hard error, deployment fails
- Missing checkpoint? Hard error
- No LLM calls, no API keys, 100x faster

## Why This Matters

**Before Vibesafe:**
```
Write code â†’ Ask AI â†’ Copy-paste â†’ Manual review â†’ Hope â†’ Deploy â†’ ðŸ”¥
```

**With Vibesafe:**
```
Write spec â†’ vibesafe compile â†’ vibesafe test â†’ git commit â†’ Deploy â†’ âœ…
```

The diff is version-controlled. The tests are automatic. The deployments are reproducible.

## Not Just Functions

Works with FastAPI endpoints too:

```python
@vibesafe
async def calculate(a: int, b: int, op: str) -> dict[str, int]:
    """
    Perform arithmetic.

    >>> import anyio
    >>> anyio.run(calculate, 5, 3, "add")
    {'result': 8}
    """
    if op not in ["add", "subtract", "multiply", "divide"]:
        raise ValueError(f"Invalid operation: {op}")
    raise VibeCoded()
```

Mount to FastAPI, get automatic endpoints. With health checks. And dependency freezing.

## What You Get

<CardGrid>
  <Card title="Deterministic Builds" icon="approve-check">
    Same spec hash = same code. No more "works on my machine" with AI generation.
  </Card>
  <Card title="Automatic Testing" icon="checklist">
    Doctests + mypy + ruff must pass before save. Bad code can't reach production.
  </Card>
  <Card title="Drift Detection" icon="warning">
    Spec changed? Hash changes. CI catches it. No silent breakage.
  </Card>
  <Card title="Zero Runtime Overhead" icon="rocket">
    Prod mode just loads Python files. No LLM calls, no latency.
  </Card>
</CardGrid>

## Real Talk

**What Vibesafe is:**
- A build tool for AI-generated code
- Content-addressed storage for implementations (like Git for code generation)
- A way to treat specs as source and implementations as artifacts

**What it's not:**
- A replacement for Copilot (different workflow)
- A magic solution (you still write specs and tests)
- Production-ready for stateful/side-effectful code (use carefully)

**Limitations we know about:**
- Scan only finds files in `app/`, `src/`, root (workarounds exist)
- Generated code quality depends on spec quality (garbage in, garbage out)
- Requires Python 3.12+ (we use modern type hints heavily)

## Get Started

Takes ~10 minutes to go from zero to first AI-generated function:

1. [Install Vibesafe](/getting-started/installation) - `uv pip install vibesafe`
2. [Configure it](/getting-started/configuration) - Create `vibesafe.toml`, set API key
3. [Write your first spec](/getting-started/first-spec) - Tutorial with working examples
4. [Learn the concepts](/core-concepts/) - Understand hashing, modes, architecture

Or just clone the repo and check out the `examples/` directory for working code.

## Open Source

MIT licensed. [GitHub repo](https://github.com/julep-ai/vibesafe). PRs welcome.

Built by the team at [Julep](https://julep.ai) because we needed it for our own AI infrastructure.
